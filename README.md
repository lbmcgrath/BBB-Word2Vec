# BBB-Word2Vec
Word Vectors with Word2vec – Fri 31 March 2017, 3.30-5.30pm

Teddy Roland, University of California, Santa Barbara

Word vectors, which have been developed by computer scientists in the field of machine learning, offer ways of representing the relationships between terms in a corpus in ways that provide “a spatial analogy to relationships between words” (Schmidt) and that suggest new ways to understand the formation and operation of discourses. This workshop uses one model for generating word vectors, word2vec, to explain how distance between terms is calculated by these models, and will show participants how to create, and how to begin to interpret, their own word embedding models.

This repository contains the slideshow and Jupyter Notebook that will be used for this workshop. The notebook was written in Python 3 and requires several standard NLP packages: numpy, scipy, pandas, sklearn, nltk, gensim.
